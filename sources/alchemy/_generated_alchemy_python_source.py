# ==============================================================================
# Merged Lakeflow Source: alchemy
# ==============================================================================
# This file is auto-generated by tools/scripts/merge_python_source.py
# Do not edit manually. Make changes to the source files instead.
# ==============================================================================

from datetime import datetime, timezone
from decimal import Decimal
from typing import (
    Any,
    Dict,
    Iterator,
    List,
    Optional,
)
import json

from pyspark.sql import Row
from pyspark.sql.datasource import DataSource, DataSourceReader, SimpleDataSourceStreamReader
from urllib.parse import urlencode
from pyspark.sql.types import *
import base64
import requests


def register_lakeflow_source(spark):
    """Register the Lakeflow Python source with Spark."""

    ########################################################
    # libs/utils.py
    ########################################################

    def _parse_struct(value: Any, field_type: StructType) -> Row:
        """Parse a dictionary into a PySpark Row based on StructType schema."""
        if not isinstance(value, dict):
            raise ValueError(f"Expected a dictionary for StructType, got {type(value)}")
        # Spark Python -> Arrow conversion require missing StructType fields to be assigned None.
        if value == {}:
            raise ValueError(
                "field in StructType cannot be an empty dict. "
                "Please assign None as the default value instead."
            )
        field_dict = {}
        for field in field_type.fields:
            if field.name in value:
                field_dict[field.name] = parse_value(value.get(field.name), field.dataType)
            elif field.nullable:
                field_dict[field.name] = None
            else:
                raise ValueError(f"Field {field.name} is not nullable but not found in the input")
        return Row(**field_dict)


    def _parse_array(value: Any, field_type: ArrayType) -> list:
        """Parse a list into a PySpark array based on ArrayType schema."""
        if not isinstance(value, list):
            if field_type.containsNull:
                return [parse_value(value, field_type.elementType)]
            raise ValueError(f"Expected a list for ArrayType, got {type(value)}")
        return [parse_value(v, field_type.elementType) for v in value]


    def _parse_map(value: Any, field_type: MapType) -> dict:
        """Parse a dictionary into a PySpark map based on MapType schema."""
        if not isinstance(value, dict):
            raise ValueError(f"Expected a dictionary for MapType, got {type(value)}")
        return {
            parse_value(k, field_type.keyType): parse_value(v, field_type.valueType)
            for k, v in value.items()
        }


    def _parse_string(value: Any) -> str:
        """Convert value to string."""
        return str(value)


    def _parse_integer(value: Any) -> int:
        """Convert value to integer."""
        if isinstance(value, str) and value.strip():
            return int(float(value)) if "." in value else int(value)
        if isinstance(value, (int, float)):
            return int(value)
        raise ValueError(f"Cannot convert {value} to integer")


    def _parse_float(value: Any) -> float:
        """Convert value to float."""
        return float(value)


    def _parse_decimal(value: Any) -> Decimal:
        """Convert value to Decimal."""
        return Decimal(value) if isinstance(value, str) and value.strip() else Decimal(str(value))


    def _parse_boolean(value: Any) -> bool:
        """Convert value to boolean."""
        if isinstance(value, str):
            lowered = value.lower()
            if lowered in ("true", "t", "yes", "y", "1"):
                return True
            if lowered in ("false", "f", "no", "n", "0"):
                return False
        return bool(value)


    def _parse_date(value: Any) -> datetime.date:
        """Convert value to date."""
        if isinstance(value, str):
            for fmt in ("%Y-%m-%d", "%m/%d/%Y", "%d-%m-%Y", "%Y/%m/%d"):
                try:
                    return datetime.strptime(value, fmt).date()
                except ValueError:
                    continue
            return datetime.fromisoformat(value).date()
        if isinstance(value, datetime):
            return value.date()
        raise ValueError(f"Cannot convert {value} to date")


    def _parse_timestamp(value: Any) -> datetime:
        """Convert value to timestamp."""
        if isinstance(value, str):
            ts_value = value.replace("Z", "+00:00") if value.endswith("Z") else value
            try:
                return datetime.fromisoformat(ts_value)
            except ValueError:
                for fmt in ("%Y-%m-%d %H:%M:%S", "%Y/%m/%d %H:%M:%S"):
                    try:
                        return datetime.strptime(ts_value, fmt)
                    except ValueError:
                        continue
        elif isinstance(value, (int, float)):
            return datetime.fromtimestamp(value)
        elif isinstance(value, datetime):
            return value
        raise ValueError(f"Cannot convert {value} to timestamp")


    def _decode_string_to_bytes(value: str) -> bytes:
        """Try to decode a string as base64, then hex, then UTF-8."""
        try:
            return base64.b64decode(value)
        except Exception:
            pass
        try:
            return bytes.fromhex(value)
        except Exception:
            pass
        return value.encode("utf-8")


    def _parse_binary(value: Any) -> bytes:
        """Convert value to bytes. Tries base64, then hex, then UTF-8 for strings."""
        if isinstance(value, bytes):
            return value
        if isinstance(value, bytearray):
            return bytes(value)
        if isinstance(value, str):
            return _decode_string_to_bytes(value)
        if isinstance(value, list):
            return bytes(value)
        return str(value).encode("utf-8")


    # Mapping of primitive types to their parser functions
    _PRIMITIVE_PARSERS = {
        StringType: _parse_string,
        IntegerType: _parse_integer,
        LongType: _parse_integer,
        FloatType: _parse_float,
        DoubleType: _parse_float,
        DecimalType: _parse_decimal,
        BooleanType: _parse_boolean,
        DateType: _parse_date,
        TimestampType: _parse_timestamp,
        BinaryType: _parse_binary,
    }


    def parse_value(value: Any, field_type: DataType) -> Any:
        """
        Converts a JSON value into a PySpark-compatible data type based on the provided field type.
        """
        if value is None:
            return None

        # Handle complex types
        if isinstance(field_type, StructType):
            return _parse_struct(value, field_type)
        if isinstance(field_type, ArrayType):
            return _parse_array(value, field_type)
        if isinstance(field_type, MapType):
            return _parse_map(value, field_type)

        # Handle primitive types via type-based lookup
        try:
            field_type_class = type(field_type)
            if field_type_class in _PRIMITIVE_PARSERS:
                return _PRIMITIVE_PARSERS[field_type_class](value)

            # Check for custom UDT handling
            if hasattr(field_type, "fromJson"):
                return field_type.fromJson(value)

            raise TypeError(f"Unsupported field type: {field_type}")
        except (ValueError, TypeError) as e:
            raise ValueError(f"Error converting '{value}' ({type(value)}) to {field_type}: {str(e)}")


    ########################################################
    # sources/alchemy/alchemy.py
    ########################################################

    SUPPORTED_NETWORKS = {
        # Ethereum & L2s
        'eth-mainnet', 'eth-sepolia', 'eth-holesky',
        'arb-mainnet', 'arb-sepolia', 'opt-mainnet', 'opt-sepolia',
        'base-mainnet', 'base-sepolia',
        # Polygon
        'polygon-mainnet', 'polygon-amoy', 'polygonzkevm-mainnet',
        # Other EVM
        'bnb-mainnet', 'avax-mainnet', 'linea-mainnet',
        'zksync-mainnet', 'scroll-mainnet', 'blast-mainnet',
        # Solana
        'solana-mainnet', 'solana-devnet'
    }

    class LakeflowConnect:
        def __init__(self, options: Dict[str, str]) -> None:
            """
            Initialize the Alchemy connector with API credentials and configuration.
            """
            self.api_key = options.get("api_key")
            if not self.api_key:
                raise ValueError("API key is required")

            self.default_network = options.get("network", "eth-mainnet")
            if self.default_network not in SUPPORTED_NETWORKS:
                raise ValueError(f"Unsupported network: {self.default_network}")

            # Base URLs for different APIs
            self.nft_base_url = "https://{network}.g.alchemy.com/nft/v3/{api_key}"
            self.prices_base_url = "https://api.g.alchemy.com/prices/v1/{api_key}"
            self.portfolio_base_url = "https://api.g.alchemy.com/data/v1/{api_key}"
            self.webhooks_base_url = "https://dashboard.alchemy.com/api"

            # Auth token for webhooks (optional, only needed for webhook endpoints)
            self.webhook_auth_token = options.get("webhook_auth_token")

            # Table configurations
            self._table_configs = {
                # NFT Tables
                "nfts_by_owner": {
                    "endpoint": "/getNFTsForOwner",
                    "api_type": "nft",
                    "primary_keys": ["owner", "contract", "tokenId"],
                    "cursor_field": "updatedAt",
                    "ingestion_type": "append",
                    "supports_pagination": True,
                    "required_params": ["owner_address"],
                    "optional_params": ["contract_addresses", "with_metadata", "page_size"]
                },
                "nfts_for_contract": {
                    "endpoint": "/getNFTsForContract",
                    "api_type": "nft",
                    "primary_keys": ["contract", "tokenId"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["contract_address"],
                    "optional_params": ["with_metadata", "start_token", "limit"]
                },
                "nft_metadata": {
                    "endpoint": "/getNFTMetadata",
                    "api_type": "nft",
                    "primary_keys": ["contract", "tokenId"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["contract_address", "token_id"],
                    "optional_params": ["token_type", "refresh_cache"]
                },
                "contract_metadata": {
                    "endpoint": "/getContractMetadata",
                    "api_type": "nft",
                    "primary_keys": ["contractAddress"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["contract_address"],
                    "optional_params": []
                },
                "nft_metadata_batch": {
                    "endpoint": "/getNFTMetadataBatch",
                    "api_type": "nft",
                    "method": "POST",
                    "primary_keys": ["contract", "tokenId"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["tokens"],
                    "optional_params": ["token_uri_timeout_in_ms", "refresh_cache"]
                },
                "contract_metadata_batch": {
                    "endpoint": "/getContractMetadataBatch",
                    "api_type": "nft",
                    "method": "POST",
                    "primary_keys": ["contractAddress"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["contract_addresses"],
                    "optional_params": []
                },
                "nft_sales": {
                    "endpoint": "/getNFTSales",
                    "api_type": "nft",
                    "primary_keys": ["contractAddress", "tokenId", "transactionHash", "logIndex"],
                    "cursor_field": "blockNumber",
                    "ingestion_type": "cdc",
                    "supports_pagination": True,
                    "required_params": [],
                    "optional_params": ["contract_address", "token_id", "from_block", "to_block", "order", "page_key"]
                },
                "floor_prices": {
                    "endpoint": "/getFloorPrice",
                    "api_type": "nft",
                    "primary_keys": ["contractAddress"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["contract_address"],
                    "optional_params": []
                },
                # Token/Price Tables
                "token_prices": {
                    "endpoint": "/tokens/by-symbol",
                    "api_type": "prices",
                    "primary_keys": ["symbol"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["symbols"],
                    "optional_params": []
                },
                "token_prices_by_address": {
                    "endpoint": "/tokens/by-address",
                    "api_type": "prices",
                    "method": "POST",
                    "primary_keys": ["network", "address"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["addresses"],
                    "optional_params": []
                },
                "token_prices_historical": {
                    "endpoint": "/tokens/historical",
                    "api_type": "prices",
                    "method": "POST",
                    "primary_keys": ["symbol", "timestamp"],
                    "cursor_field": "timestamp",
                    "ingestion_type": "cdc",
                    "supports_pagination": False,
                    "required_params": ["start_time", "end_time"],
                    "optional_params": ["symbol", "network", "address", "interval"]
                },
                # Portfolio Tables
                "tokens_by_wallet": {
                    "endpoint": "/getTokensByWallet",
                    "api_type": "portfolio",
                    "method": "POST",
                    "primary_keys": ["wallet_address", "network", "contractAddress"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["addresses"],
                    "optional_params": ["with_metadata", "with_prices", "include_native_tokens", "include_erc20_tokens"]
                },
                "token_balances_by_wallet": {
                    "endpoint": "/getTokenBalancesByWallet",
                    "api_type": "portfolio",
                    "method": "POST",
                    "primary_keys": ["wallet_address", "network", "contractAddress"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["addresses"],
                    "optional_params": ["include_native_tokens", "include_erc20_tokens"]
                },
                "nfts_by_wallet": {
                    "endpoint": "/getNftsByWallet",
                    "api_type": "portfolio",
                    "method": "POST",
                    "primary_keys": ["wallet_address", "network", "contractAddress", "tokenId"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": True,
                    "required_params": ["addresses"],
                    "optional_params": ["with_metadata", "page_size"]
                },
                "nft_collections_by_wallet": {
                    "endpoint": "/getNftCollectionsByWallet",
                    "api_type": "portfolio",
                    "method": "POST",
                    "primary_keys": ["wallet_address", "network", "contractAddress"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["addresses"],
                    "optional_params": ["with_metadata"]
                },
                "wallet_transactions": {
                    "endpoint": "/getTransactionsByWallet",
                    "api_type": "portfolio",
                    "method": "POST",
                    "primary_keys": ["hash", "network"],
                    "cursor_field": "blockNum",
                    "ingestion_type": "cdc",
                    "supports_pagination": True,
                    "required_params": ["addresses"],
                    "optional_params": ["page_size", "page_key", "from_block", "to_block", "from_timestamp", "to_timestamp", "category", "order"]
                },
                # Webhook Tables
                "webhooks": {
                    "endpoint": "/team-webhooks",
                    "api_type": "webhooks",
                    "primary_keys": ["id"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": [],
                    "optional_params": []
                },
                "webhook_addresses": {
                    "endpoint": "/webhook-addresses",
                    "api_type": "webhooks",
                    "primary_keys": ["webhook_id", "address"],
                    "cursor_field": None,
                    "ingestion_type": "snapshot",
                    "supports_pagination": False,
                    "required_params": ["webhook_id"],
                    "optional_params": ["limit", "after"]
                }
            }

        def list_tables(self) -> List[str]:
            """
            List all supported tables.
            """
            return list(self._table_configs.keys())

        def get_table_schema(self, table_name: str, table_options: Dict[str, str]) -> StructType:
            """
            Get the schema for a table.
            """
            if table_name not in self._table_configs:
                raise ValueError(f"Unknown table: {table_name}")

            config = self._table_configs[table_name]

            if table_name == "nfts_by_owner":
                return StructType([
                    StructField("owner", StringType(), False),
                    StructField("contract", StructType([
                        StructField("address", StringType(), False),
                        StructField("name", StringType(), True),
                        StructField("symbol", StringType(), True),
                        StructField("totalSupply", StringType(), True),
                        StructField("tokenType", StringType(), True),
                        StructField("contractDeployer", StringType(), True),
                        StructField("deployedBlockNumber", LongType(), True),
                        StructField("openSea", StructType([
                            StructField("floorPrice", DoubleType(), True),
                            StructField("collectionName", StringType(), True),
                            StructField("safelistRequestStatus", StringType(), True),
                            StructField("imageUrl", StringType(), True),
                            StructField("description", StringType(), True),
                            StructField("externalUrl", StringType(), True),
                            StructField("twitterUsername", StringType(), True),
                            StructField("discordUrl", StringType(), True),
                            StructField("lastIngestedAt", StringType(), True),
                        ]), True),
                    ]), False),
                    StructField("tokenId", StringType(), False),
                    StructField("tokenType", StringType(), True),
                    StructField("title", StringType(), True),
                    StructField("description", StringType(), True),
                    StructField("timeLastUpdated", StringType(), True),
                    StructField("metadataError", StringType(), True),
                    StructField("rawMetadata", StructType([
                        StructField("name", StringType(), True),
                        StructField("description", StringType(), True),
                        StructField("image", StringType(), True),
                        StructField("external_url", StringType(), True),
                        StructField("attributes", ArrayType(StructType([
                            StructField("value", StringType(), True),
                            StructField("trait_type", StringType(), True),
                            StructField("display_type", StringType(), True),
                        ])), True),
                    ]), True),
                    StructField("tokenUri", StructType([
                        StructField("raw", StringType(), True),
                        StructField("gateway", StringType(), True),
                    ]), True),
                    StructField("media", ArrayType(StructType([
                        StructField("raw", StringType(), True),
                        StructField("gateway", StringType(), True),
                        StructField("thumbnail", StringType(), True),
                        StructField("format", StringType(), True),
                        StructField("bytes", LongType(), True),
                    ])), True),
                    StructField("balance", StringType(), True),
                    StructField("acquiredAt", StructType([
                        StructField("blockTimestamp", StringType(), True),
                        StructField("blockNumber", LongType(), True),
                    ]), True),
                ])

            elif table_name == "nfts_for_contract":
                return StructType([
                    StructField("contract", StructType([
                        StructField("address", StringType(), False),
                        StructField("name", StringType(), True),
                        StructField("symbol", StringType(), True),
                        StructField("totalSupply", StringType(), True),
                        StructField("tokenType", StringType(), True),
                    ]), False),
                    StructField("tokenId", StringType(), False),
                    StructField("tokenType", StringType(), True),
                    StructField("title", StringType(), True),
                    StructField("description", StringType(), True),
                    StructField("timeLastUpdated", StringType(), True),
                    StructField("metadataError", StringType(), True),
                    StructField("rawMetadata", StructType([
                        StructField("name", StringType(), True),
                        StructField("description", StringType(), True),
                        StructField("image", StringType(), True),
                        StructField("external_url", StringType(), True),
                        StructField("attributes", ArrayType(StructType([
                            StructField("value", StringType(), True),
                            StructField("trait_type", StringType(), True),
                        ])), True),
                    ]), True),
                    StructField("tokenUri", StructType([
                        StructField("raw", StringType(), True),
                        StructField("gateway", StringType(), True),
                    ]), True),
                    StructField("media", ArrayType(StructType([
                        StructField("raw", StringType(), True),
                        StructField("gateway", StringType(), True),
                        StructField("thumbnail", StringType(), True),
                        StructField("format", StringType(), True),
                        StructField("bytes", LongType(), True),
                    ])), True),
                ])

            elif table_name == "nft_metadata":
                return StructType([
                    StructField("contract", StructType([
                        StructField("address", StringType(), False),
                        StructField("name", StringType(), True),
                        StructField("symbol", StringType(), True),
                        StructField("totalSupply", StringType(), True),
                        StructField("tokenType", StringType(), True),
                    ]), False),
                    StructField("tokenId", StringType(), False),
                    StructField("tokenType", StringType(), True),
                    StructField("title", StringType(), True),
                    StructField("description", StringType(), True),
                    StructField("timeLastUpdated", StringType(), True),
                    StructField("metadataError", StringType(), True),
                    StructField("rawMetadata", StructType([
                        StructField("name", StringType(), True),
                        StructField("description", StringType(), True),
                        StructField("image", StringType(), True),
                        StructField("external_url", StringType(), True),
                        StructField("attributes", ArrayType(StructType([
                            StructField("value", StringType(), True),
                            StructField("trait_type", StringType(), True),
                            StructField("display_type", StringType(), True),
                        ])), True),
                    ]), True),
                    StructField("tokenUri", StructType([
                        StructField("raw", StringType(), True),
                        StructField("gateway", StringType(), True),
                    ]), True),
                    StructField("media", ArrayType(StructType([
                        StructField("raw", StringType(), True),
                        StructField("gateway", StringType(), True),
                        StructField("thumbnail", StringType(), True),
                        StructField("format", StringType(), True),
                        StructField("bytes", LongType(), True),
                    ])), True),
                ])

            elif table_name == "contract_metadata":
                return StructType([
                    StructField("contractAddress", StringType(), False),
                    StructField("name", StringType(), True),
                    StructField("symbol", StringType(), True),
                    StructField("totalSupply", StringType(), True),
                    StructField("tokenType", StringType(), True),
                    StructField("contractDeployer", StringType(), True),
                    StructField("deployedBlockNumber", LongType(), True),
                    StructField("openSea", StructType([
                        StructField("floorPrice", DoubleType(), True),
                        StructField("collectionName", StringType(), True),
                        StructField("safelistRequestStatus", StringType(), True),
                        StructField("imageUrl", StringType(), True),
                        StructField("description", StringType(), True),
                        StructField("externalUrl", StringType(), True),
                        StructField("twitterUsername", StringType(), True),
                        StructField("discordUrl", StringType(), True),
                        StructField("lastIngestedAt", StringType(), True),
                    ]), True),
                ])

            elif table_name == "nft_sales":
                return StructType([
                    StructField("contractAddress", StringType(), True),
                    StructField("tokenId", StringType(), True),
                    StructField("quantity", StringType(), True),
                    StructField("transactionHash", StringType(), False),
                    StructField("blockNumber", LongType(), False),
                    StructField("logIndex", LongType(), False),
                    StructField("bundleIndex", LongType(), True),
                    StructField("transactionIndex", LongType(), True),
                    StructField("buyerAddress", StringType(), True),
                    StructField("sellerAddress", StringType(), True),
                    StructField("marketplace", StringType(), True),
                    StructField("price", StructType([
                        StructField("amount", StringType(), True),
                        StructField("currency", StructType([
                            StructField("contractAddress", StringType(), True),
                            StructField("symbol", StringType(), True),
                            StructField("decimals", LongType(), True),
                        ]), True),
                        StructField("marketplaceFee", StringType(), True),
                        StructField("creatorFee", StringType(), True),
                        StructField("royaltyFee", StringType(), True),
                    ]), True),
                ])

            elif table_name == "floor_prices":
                return StructType([
                    StructField("contractAddress", StringType(), False),
                    StructField("openSea", StructType([
                        StructField("floorPrice", DoubleType(), True),
                        StructField("priceCurrency", StringType(), True),
                        StructField("retrievedAt", StringType(), True),
                    ]), True),
                    StructField("looksRare", StructType([
                        StructField("floorPrice", DoubleType(), True),
                        StructField("priceCurrency", StringType(), True),
                        StructField("retrievedAt", StringType(), True),
                    ]), True),
                ])

            elif table_name == "token_prices":
                return StructType([
                    StructField("symbol", StringType(), False),
                    StructField("prices", ArrayType(StructType([
                        StructField("currency", StringType(), False),
                        StructField("value", StringType(), False),
                    ])), False),
                ])

            elif table_name == "token_prices_historical":
                return StructType([
                    StructField("symbol", StringType(), False),
                    StructField("timestamp", LongType(), False),
                    StructField("value", DoubleType(), True),
                    StructField("marketCap", DoubleType(), True),
                    StructField("volume24h", DoubleType(), True),
                ])

            elif table_name == "tokens_by_wallet":
                return StructType([
                    StructField("wallet_address", StringType(), False),
                    StructField("network", StringType(), False),
                    StructField("contractAddress", StringType(), True),
                    StructField("tokenBalance", StringType(), True),
                    StructField("decimals", LongType(), True),
                    StructField("name", StringType(), True),
                    StructField("symbol", StringType(), True),
                    StructField("logo", StringType(), True),
                    StructField("price", DoubleType(), True),
                    StructField("network", StringType(), True),
                ])

            elif table_name == "token_balances_by_wallet":
                return StructType([
                    StructField("wallet_address", StringType(), False),
                    StructField("network", StringType(), False),
                    StructField("contractAddress", StringType(), True),
                    StructField("tokenBalance", StringType(), True),
                    StructField("error", StringType(), True),
                ])

            elif table_name == "nfts_by_wallet":
                return StructType([
                    StructField("wallet_address", StringType(), False),
                    StructField("network", StringType(), False),
                    StructField("contractAddress", StringType(), False),
                    StructField("tokenId", StringType(), False),
                    StructField("balance", StringType(), True),
                ])

            elif table_name == "wallet_transactions":
                return StructType([
                    StructField("hash", StringType(), False),
                    StructField("network", StringType(), False),
                    StructField("blockNum", StringType(), False),
                    StructField("from", StringType(), True),
                    StructField("to", StringType(), True),
                    StructField("value", StringType(), True),
                    StructField("gasPrice", StringType(), True),
                    StructField("gasUsed", StringType(), True),
                    StructField("timestamp", LongType(), True),
                    StructField("category", StringType(), True),
                    StructField("asset", StringType(), True),
                    StructField("contractAddress", StringType(), True),
                    StructField("erc721TokenId", StringType(), True),
                    StructField("erc1155Metadata", ArrayType(StructType([
                        StructField("tokenId", StringType(), True),
                        StructField("value", StringType(), True),
                    ])), True),
                    StructField("logEvents", ArrayType(StructType([
                        StructField("contractAddress", StringType(), True),
                        StructField("topics", ArrayType(StringType()), True),
                        StructField("data", StringType(), True),
                    ])), True),
                ])

            elif table_name == "webhooks":
                return StructType([
                    StructField("id", StringType(), False),
                    StructField("network", StringType(), True),
                    StructField("webhook_type", StringType(), True),
                    StructField("webhook_url", StringType(), True),
                    StructField("is_active", BooleanType(), True),
                    StructField("time_created", LongType(), True),
                    StructField("addresses", ArrayType(StringType()), True),
                ])

            elif table_name == "webhook_addresses":
                return StructType([
                    StructField("webhook_id", StringType(), False),
                    StructField("address", StringType(), False),
                ])

            elif table_name == "nft_metadata_batch":
                # Same schema as individual NFT metadata
                return StructType([
                    StructField("contract", StructType([
                        StructField("address", StringType(), False),
                        StructField("name", StringType(), True),
                        StructField("symbol", StringType(), True),
                        StructField("totalSupply", StringType(), True),
                        StructField("tokenType", StringType(), True),
                    ]), False),
                    StructField("tokenId", StringType(), False),
                    StructField("tokenType", StringType(), True),
                    StructField("title", StringType(), True),
                    StructField("description", StringType(), True),
                    StructField("timeLastUpdated", StringType(), True),
                    StructField("metadataError", StringType(), True),
                    StructField("rawMetadata", StructType([
                        StructField("name", StringType(), True),
                        StructField("description", StringType(), True),
                        StructField("image", StringType(), True),
                        StructField("external_url", StringType(), True),
                        StructField("attributes", ArrayType(StructType([
                            StructField("value", StringType(), True),
                            StructField("trait_type", StringType(), True),
                            StructField("display_type", StringType(), True),
                        ])), True),
                    ]), True),
                    StructField("tokenUri", StructType([
                        StructField("raw", StringType(), True),
                        StructField("gateway", StringType(), True),
                    ]), True),
                    StructField("media", ArrayType(StructType([
                        StructField("raw", StringType(), True),
                        StructField("gateway", StringType(), True),
                        StructField("thumbnail", StringType(), True),
                        StructField("format", StringType(), True),
                        StructField("bytes", LongType(), True),
                    ])), True),
                ])

            elif table_name == "contract_metadata_batch":
                # Same schema as individual contract metadata
                return StructType([
                    StructField("contractAddress", StringType(), False),
                    StructField("name", StringType(), True),
                    StructField("symbol", StringType(), True),
                    StructField("totalSupply", StringType(), True),
                    StructField("tokenType", StringType(), True),
                    StructField("contractDeployer", StringType(), True),
                    StructField("deployedBlockNumber", LongType(), True),
                    StructField("openSea", StructType([
                        StructField("floorPrice", DoubleType(), True),
                        StructField("collectionName", StringType(), True),
                        StructField("safelistRequestStatus", StringType(), True),
                        StructField("imageUrl", StringType(), True),
                        StructField("description", StringType(), True),
                        StructField("externalUrl", StringType(), True),
                        StructField("twitterUsername", StringType(), True),
                        StructField("discordUrl", StringType(), True),
                        StructField("lastIngestedAt", StringType(), True),
                    ]), True),
                ])

            elif table_name == "token_prices_by_address":
                # Similar to token_prices but with network/address instead of symbol
                return StructType([
                    StructField("network", StringType(), False),
                    StructField("address", StringType(), False),
                    StructField("prices", ArrayType(StructType([
                        StructField("currency", StringType(), False),
                        StructField("value", StringType(), False),
                    ])), False),
                ])

            elif table_name == "nft_collections_by_wallet":
                return StructType([
                    StructField("wallet_address", StringType(), False),
                    StructField("network", StringType(), False),
                    StructField("contractAddress", StringType(), False),
                    StructField("name", StringType(), True),
                    StructField("symbol", StringType(), True),
                    StructField("tokenType", StringType(), True),
                    StructField("openSea", StructType([
                        StructField("floorPrice", DoubleType(), True),
                        StructField("collectionName", StringType(), True),
                        StructField("safelistRequestStatus", StringType(), True),
                        StructField("imageUrl", StringType(), True),
                        StructField("description", StringType(), True),
                        StructField("externalUrl", StringType(), True),
                    ]), True),
                    StructField("totalBalance", StringType(), True),
                    StructField("distinctNftsOwned", LongType(), True),
                    StructField("distinctTokensOwned", LongType(), True),
                ])

            else:
                raise ValueError(f"Schema not implemented for table: {table_name}")

        def read_table_metadata(self, table_name: str, table_options: Dict[str, str]) -> Dict:
            """
            Get metadata for a table.
            """
            if table_name not in self._table_configs:
                raise ValueError(f"Unknown table: {table_name}")

            config = self._table_configs[table_name]
            return {
                "primary_keys": config["primary_keys"],
                "cursor_field": config["cursor_field"],
                "ingestion_type": config["ingestion_type"],
            }

        def read_table(
            self, table_name: str, start_offset: Dict, table_options: Dict[str, str]
        ) -> (Iterator[Dict], Dict):
            """
            Read data from a table.
            """
            if table_name not in self._table_configs:
                raise ValueError(f"Unknown table: {table_name}")

            config = self._table_configs[table_name]

            # Validate required parameters
            for param in config["required_params"]:
                if param not in table_options and param not in start_offset:
                    raise ValueError(f"Required parameter '{param}' not provided for table '{table_name}'")

            # Build API URL and request data
            url, request_data = self._build_api_request(table_name, table_options, start_offset)

            # Make API request (GET or POST)
            method = config.get("method", "GET")
            if method == "POST":
                response = requests.post(url, json=request_data, headers={"Content-Type": "application/json"})
            else:
                response = requests.get(url, params=request_data)

            response.raise_for_status()
            data = response.json()

            # Process response based on table type
            records = self._process_api_response(table_name, data, table_options)

            # Calculate next offset
            next_offset = self._calculate_next_offset(table_name, data, start_offset)

            return iter(records), next_offset

        def _build_api_request(self, table_name: str, table_options: Dict[str, str], start_offset: Dict) -> (str, Dict):
            """
            Build API request URL and request data (query params for GET, JSON body for POST).
            """
            config = self._table_configs[table_name]
            network = table_options.get("network", self.default_network)
            method = config.get("method", "GET")

            if config["api_type"] == "nft":
                base_url = self.nft_base_url.format(network=network, api_key=self.api_key)
                url = f"{base_url}{config['endpoint']}"
            elif config["api_type"] == "prices":
                base_url = self.prices_base_url.format(api_key=self.api_key)
                url = f"{base_url}{config['endpoint']}"
            elif config["api_type"] == "portfolio":
                base_url = self.portfolio_base_url.format(api_key=self.api_key)
                url = f"{base_url}{config['endpoint']}"
            elif config["api_type"] == "webhooks":
                url = f"{self.webhooks_base_url}{config['endpoint']}"
            else:
                raise ValueError(f"Unknown API type: {config['api_type']}")

            # For GET requests, build query parameters
            if method == "GET":
                params = {}
                self._build_get_params(table_name, table_options, start_offset, params)
                return url, params

            # For POST requests, build JSON body
            else:
                body = {}
                self._build_post_body(table_name, table_options, start_offset, body)
                return url, body

        def _build_get_params(self, table_name: str, table_options: Dict[str, str], start_offset: Dict, params: Dict):
            """Build query parameters for GET requests."""
            if table_name == "nfts_by_owner":
                params["owner"] = table_options["owner_address"]
                if "contract_addresses" in table_options:
                    params["contractAddresses"] = table_options["contract_addresses"].split(",")
                params["withMetadata"] = table_options.get("with_metadata", "true").lower() == "true"
                params["pageSize"] = int(table_options.get("page_size", "100"))
                if start_offset and "pageKey" in start_offset:
                    params["pageKey"] = start_offset["pageKey"]

            elif table_name == "nfts_for_contract":
                params["contractAddress"] = table_options["contract_address"]
                params["withMetadata"] = table_options.get("with_metadata", "true").lower() == "true"
                if "start_token" in table_options:
                    params["startToken"] = table_options["start_token"]
                if "limit" in table_options:
                    params["limit"] = int(table_options["limit"])

            elif table_name == "nft_metadata":
                params["contractAddress"] = table_options["contract_address"]
                params["tokenId"] = table_options["token_id"]
                if "token_type" in table_options:
                    params["tokenType"] = table_options["token_type"]
                if "refresh_cache" in table_options:
                    params["refreshCache"] = table_options["refresh_cache"].lower() == "true"

            elif table_name == "contract_metadata":
                params["contractAddress"] = table_options["contract_address"]

            elif table_name == "nft_sales":
                if "contract_address" in table_options:
                    params["contractAddress"] = table_options["contract_address"]
                if "token_id" in table_options:
                    params["tokenId"] = table_options["token_id"]
                if "from_block" in table_options:
                    params["fromBlock"] = table_options["from_block"]
                if "to_block" in table_options:
                    params["toBlock"] = table_options["to_block"]
                params["order"] = table_options.get("order", "desc")
                if start_offset and "pageKey" in start_offset:
                    params["pageKey"] = start_offset["pageKey"]

            elif table_name == "floor_prices":
                params["contractAddress"] = table_options["contract_address"]

            elif table_name == "token_prices":
                # Alchemy expects symbols as array-style query params: ?symbols=ETH&symbols=BTC
                symbols_str = table_options["symbols"]
                params["symbols"] = [s.strip() for s in symbols_str.split(",")]

            elif table_name == "webhook_addresses":
                params["webhook_id"] = table_options["webhook_id"]
                if "limit" in table_options:
                    params["limit"] = int(table_options["limit"])
                if "after" in table_options:
                    params["after"] = table_options["after"]

        def _build_post_body(self, table_name: str, table_options: Dict[str, str], start_offset: Dict, body: Dict):
            """Build JSON body for POST requests."""
            if table_name == "nft_metadata_batch":
                body["tokens"] = []
                # Parse tokens from table_options["tokens"] - expected format: "contract1:token1,contract2:token2"
                tokens_str = table_options["tokens"]
                for token_spec in tokens_str.split(","):
                    if ":" in token_spec:
                        contract, token_id = token_spec.split(":", 1)
                        body["tokens"].append({
                            "contractAddress": contract.strip(),
                            "tokenId": token_id.strip()
                        })

                if "token_uri_timeout_in_ms" in table_options:
                    body["tokenUriTimeoutInMs"] = int(table_options["token_uri_timeout_in_ms"])
                if "refresh_cache" in table_options:
                    body["refreshCache"] = table_options["refresh_cache"].lower() == "true"

            elif table_name == "contract_metadata_batch":
                body["contractAddresses"] = table_options["contract_addresses"].split(",")

            elif table_name == "token_prices_by_address":
                body["addresses"] = []
                # Parse addresses from table_options["addresses"] - expected format: "network1:address1,network2:address2"
                addresses_str = table_options["addresses"]
                for addr_spec in addresses_str.split(","):
                    if ":" in addr_spec:
                        network, address = addr_spec.split(":", 1)
                        body["addresses"].append({
                            "network": network.strip(),
                            "address": address.strip()
                        })

            elif table_name == "token_prices_historical":
                # Can use either symbol or network+address
                if "symbol" in table_options:
                    body["symbol"] = table_options["symbol"]
                elif "network" in table_options and "address" in table_options:
                    body["network"] = table_options["network"]
                    body["address"] = table_options["address"]

                body["startTime"] = table_options["start_time"]
                body["endTime"] = table_options["end_time"]
                if "interval" in table_options:
                    body["interval"] = table_options["interval"]

            elif table_name == "tokens_by_wallet":
                body["addresses"] = []
                # Parse addresses from table_options["addresses"] - expected format: "address1@network1,address2@network2"
                addresses_str = table_options["addresses"]
                for addr_spec in addresses_str.split(","):
                    if "@" in addr_spec:
                        address, networks_str = addr_spec.split("@", 1)
                        networks = [n.strip() for n in networks_str.split("|")] if "|" in networks_str else [networks_str.strip()]
                        body["addresses"].append({
                            "address": address.strip(),
                            "networks": networks
                        })

                body["withMetadata"] = table_options.get("with_metadata", "true").lower() == "true"
                body["withPrices"] = table_options.get("with_prices", "true").lower() == "true"
                body["includeNativeTokens"] = table_options.get("include_native_tokens", "true").lower() == "true"
                if "include_erc20_tokens" in table_options:
                    body["includeErc20Tokens"] = table_options["include_erc20_tokens"].lower() == "true"

            elif table_name == "token_balances_by_wallet":
                body["addresses"] = []
                addresses_str = table_options["addresses"]
                for addr_spec in addresses_str.split(","):
                    if "@" in addr_spec:
                        address, networks_str = addr_spec.split("@", 1)
                        networks = [n.strip() for n in networks_str.split("|")] if "|" in networks_str else [networks_str.strip()]
                        body["addresses"].append({
                            "address": address.strip(),
                            "networks": networks
                        })

                body["includeNativeTokens"] = table_options.get("include_native_tokens", "true").lower() == "true"
                if "include_erc20_tokens" in table_options:
                    body["includeErc20Tokens"] = table_options["include_erc20_tokens"].lower() == "true"

            elif table_name == "nfts_by_wallet":
                body["addresses"] = []
                addresses_str = table_options["addresses"]
                for addr_spec in addresses_str.split(","):
                    if "@" in addr_spec:
                        address, networks_str = addr_spec.split("@", 1)
                        networks = [n.strip() for n in networks_str.split("|")] if "|" in networks_str else [networks_str.strip()]
                        body["addresses"].append({
                            "address": address.strip(),
                            "networks": networks
                        })

                body["withMetadata"] = table_options.get("with_metadata", "true").lower() == "true"
                if "page_size" in table_options:
                    body["pageSize"] = int(table_options["page_size"])

            elif table_name == "nft_collections_by_wallet":
                body["addresses"] = []
                addresses_str = table_options["addresses"]
                for addr_spec in addresses_str.split(","):
                    if "@" in addr_spec:
                        address, networks_str = addr_spec.split("@", 1)
                        networks = [n.strip() for n in networks_str.split("|")] if "|" in networks_str else [networks_str.strip()]
                        body["addresses"].append({
                            "address": address.strip(),
                            "networks": networks
                        })

                body["withMetadata"] = table_options.get("with_metadata", "true").lower() == "true"

            elif table_name == "wallet_transactions":
                body["addresses"] = []
                addresses_str = table_options["addresses"]
                for addr_spec in addresses_str.split(","):
                    if "@" in addr_spec:
                        address, networks_str = addr_spec.split("@", 1)
                        networks = [n.strip() for n in networks_str.split("|")] if "|" in networks_str else [networks_str.strip()]
                        body["addresses"].append({
                            "address": address.strip(),
                            "networks": networks
                        })

                if "page_size" in table_options:
                    body["pageSize"] = int(table_options["page_size"])
                if "page_key" in table_options:
                    body["pageKey"] = table_options["page_key"]
                if "from_block" in table_options:
                    body["fromBlock"] = table_options["from_block"]
                if "to_block" in table_options:
                    body["toBlock"] = table_options["to_block"]
                if "from_timestamp" in table_options:
                    body["fromTimestamp"] = table_options["from_timestamp"]
                if "to_timestamp" in table_options:
                    body["toTimestamp"] = table_options["to_timestamp"]
                if "category" in table_options:
                    body["category"] = table_options["category"].split(",")
                if "order" in table_options:
                    body["order"] = table_options["order"]

        def _process_api_response(self, table_name: str, data: Dict, table_options: Dict[str, str]) -> List[Dict]:
            """
            Process API response into records.
            """
            if table_name in ["nfts_by_owner", "nfts_for_contract", "nft_metadata"]:
                return data.get("ownedNfts", []) if "ownedNfts" in data else [data] if table_name == "nft_metadata" else []

            elif table_name == "contract_metadata":
                return [data]

            elif table_name == "nft_sales":
                return data.get("nftSales", [])

            elif table_name == "floor_prices":
                return [data]

            elif table_name == "token_prices":
                return data.get("data", [])

            elif table_name == "token_prices_historical":
                return data.get("data", [])

            elif table_name in ["tokens_by_wallet", "token_balances_by_wallet"]:
                records = []
                for wallet_data in data:
                    wallet_address = wallet_data.get("address")
                    network = wallet_data.get("network", table_options.get("network", self.default_network))
                    for token in wallet_data.get("tokenBalances", []):
                        record = {
                            "wallet_address": wallet_address,
                            "network": network,
                            **token
                        }
                        records.append(record)
                return records

            elif table_name == "nfts_by_wallet":
                records = []
                for wallet_data in data:
                    wallet_address = wallet_data.get("address")
                    network = wallet_data.get("network", table_options.get("network", self.default_network))
                    for nft in wallet_data.get("nfts", []):
                        record = {
                            "wallet_address": wallet_address,
                            "network": network,
                            **nft
                        }
                        records.append(record)
                return records

            elif table_name == "wallet_transactions":
                records = []
                for wallet_data in data:
                    wallet_address = wallet_data.get("address")
                    network = wallet_data.get("network", table_options.get("network", self.default_network))
                    for tx in wallet_data.get("transactions", []):
                        record = {
                            "wallet_address": wallet_address,
                            "network": network,
                            **tx
                        }
                        records.append(record)
                return records

            elif table_name == "webhooks":
                return data.get("data", [])

            elif table_name == "webhook_addresses":
                records = []
                webhook_id = table_options["webhook_id"]
                for address in data.get("addresses", []):
                    records.append({
                        "webhook_id": webhook_id,
                        "address": address
                    })
                return records

            elif table_name == "nft_metadata_batch":
                # Response contains an array of NFT metadata objects
                return data if isinstance(data, list) else []

            elif table_name == "contract_metadata_batch":
                # Response contains an array of contract metadata objects
                return data if isinstance(data, list) else []

            elif table_name == "token_prices_by_address":
                # Similar structure to token_prices but keyed by address/network
                records = []
                for item in data.get("data", []):
                    records.append(item)
                return records

            elif table_name == "nft_collections_by_wallet":
                records = []
                for wallet_data in data:
                    wallet_address = wallet_data.get("address")
                    network = wallet_data.get("network", table_options.get("network", self.default_network))
                    for collection in wallet_data.get("collections", []):
                        record = {
                            "wallet_address": wallet_address,
                            "network": network,
                            **collection
                        }
                        records.append(record)
                return records

            return []

        def _calculate_next_offset(self, table_name: str, data: Dict, current_offset: Dict) -> Dict:
            """
            Calculate next offset for pagination.
            """
            config = self._table_configs[table_name]

            if not config["supports_pagination"]:
                return None

            if table_name in ["nfts_by_owner", "nft_sales"] and "pageKey" in data:
                return {"pageKey": data["pageKey"]}

            return None


    ########################################################
    # pipeline/lakeflow_python_source.py
    ########################################################

    METADATA_TABLE = "_lakeflow_metadata"
    TABLE_NAME = "tableName"
    TABLE_NAME_LIST = "tableNameList"
    TABLE_CONFIGS = "tableConfigs"
    IS_DELETE_FLOW = "isDeleteFlow"


    class LakeflowStreamReader(SimpleDataSourceStreamReader):
        """
        Implements a data source stream reader for Lakeflow Connect.
        Currently, only the simpleStreamReader is implemented, which uses a
        more generic protocol suitable for most data sources that support
        incremental loading.
        """

        def __init__(
            self,
            options: dict[str, str],
            schema: StructType,
            lakeflow_connect: LakeflowConnect,
        ):
            self.options = options
            self.lakeflow_connect = lakeflow_connect
            self.schema = schema

        def initialOffset(self):
            return {}

        def read(self, start: dict) -> (Iterator[tuple], dict):
            is_delete_flow = self.options.get(IS_DELETE_FLOW) == "true"
            # Strip delete flow options before passing to connector
            table_options = {
                k: v for k, v in self.options.items() if k != IS_DELETE_FLOW
            }

            if is_delete_flow:
                records, offset = self.lakeflow_connect.read_table_deletes(
                    self.options[TABLE_NAME], start, table_options
                )
            else:
                records, offset = self.lakeflow_connect.read_table(
                    self.options[TABLE_NAME], start, table_options
                )
            rows = map(lambda x: parse_value(x, self.schema), records)
            return rows, offset

        def readBetweenOffsets(self, start: dict, end: dict) -> Iterator[tuple]:
            # TODO: This does not ensure the records returned are identical across repeated calls.
            # For append-only tables, the data source must guarantee that reading from the same
            # start offset will always yield the same set of records.
            # For tables ingested as incremental CDC, it is only necessary that no new changes
            # are missed in the returned records.
            return self.read(start)[0]


    class LakeflowBatchReader(DataSourceReader):
        def __init__(
            self,
            options: dict[str, str],
            schema: StructType,
            lakeflow_connect: LakeflowConnect,
        ):
            self.options = options
            self.schema = schema
            self.lakeflow_connect = lakeflow_connect
            self.table_name = options[TABLE_NAME]

        def read(self, partition):
            all_records = []
            if self.table_name == METADATA_TABLE:
                all_records = self._read_table_metadata()
            else:
                all_records, _ = self.lakeflow_connect.read_table(
                    self.table_name, None, self.options
                )

            rows = map(lambda x: parse_value(x, self.schema), all_records)
            return iter(rows)

        def _read_table_metadata(self):
            table_name_list = self.options.get(TABLE_NAME_LIST, "")
            table_names = [o.strip() for o in table_name_list.split(",") if o.strip()]
            all_records = []
            table_configs = json.loads(self.options.get(TABLE_CONFIGS, "{}"))
            for table in table_names:
                metadata = self.lakeflow_connect.read_table_metadata(
                    table, table_configs.get(table, {})
                )
                all_records.append({TABLE_NAME: table, **metadata})
            return all_records


    class LakeflowSource(DataSource):
        def __init__(self, options):
            self.options = options
            self.lakeflow_connect = LakeflowConnect(options)

        @classmethod
        def name(cls):
            return "lakeflow_connect"

        def schema(self):
            table = self.options[TABLE_NAME]
            if table == METADATA_TABLE:
                return StructType(
                    [
                        StructField(TABLE_NAME, StringType(), False),
                        StructField("primary_keys", ArrayType(StringType()), True),
                        StructField("cursor_field", StringType(), True),
                        StructField("ingestion_type", StringType(), True),
                    ]
                )
            else:
                # Assuming the LakeflowConnect interface uses get_table_schema, not get_table_details
                return self.lakeflow_connect.get_table_schema(table, self.options)

        def reader(self, schema: StructType):
            return LakeflowBatchReader(self.options, schema, self.lakeflow_connect)

        def simpleStreamReader(self, schema: StructType):
            return LakeflowStreamReader(self.options, schema, self.lakeflow_connect)


    spark.dataSource.register(LakeflowSource)  # pylint: disable=undefined-variable
