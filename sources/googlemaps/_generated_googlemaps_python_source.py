# ==============================================================================
# Merged Lakeflow Source: googlemaps
# ==============================================================================
# This file is auto-generated by tools/scripts/merge_python_source.py
# Do not edit manually. Make changes to the source files instead.
# ==============================================================================

from datetime import datetime
from decimal import Decimal
from typing import (
    Any,
    Dict,
    Iterator,
    List,
    Tuple,
)

from pyspark.sql import Row
from pyspark.sql.datasource import DataSource, DataSourceReader, SimpleDataSourceStreamReader
from pyspark.sql.types import *
import requests


def register_lakeflow_source(spark):
    """Register the Lakeflow Python source with Spark."""

    ########################################################
    # libs/utils.py
    ########################################################

    def parse_value(value: Any, field_type: DataType) -> Any:
        """
        Converts a JSON value into a PySpark-compatible data type based on the provided field type.
        """
        if value is None:
            return None
        # Handle complex types
        if isinstance(field_type, StructType):
            # Validate input for StructType
            if not isinstance(value, dict):
                raise ValueError(f"Expected a dictionary for StructType, got {type(value)}")
            # Spark Python -> Arrow conversion require missing StructType fields to be assigned None.
            if value == {}:
                raise ValueError(
                    f"field in StructType cannot be an empty dict. Please assign None as the default value instead."
                )
            # For StructType, recursively parse fields into a Row
            field_dict = {}
            for field in field_type.fields:
                # When a field does not exist in the input:
                # 1. set it to None when schema marks it as nullable
                # 2. Otherwise, raise an error.
                if field.name in value:
                    field_dict[field.name] = parse_value(value.get(field.name), field.dataType)
                elif field.nullable:
                    field_dict[field.name] = None
                else:
                    raise ValueError(f"Field {field.name} is not nullable but not found in the input")

            return Row(**field_dict)
        elif isinstance(field_type, ArrayType):
            # For ArrayType, parse each element in the array
            if not isinstance(value, list):
                # Handle edge case: single value that should be an array
                if field_type.containsNull:
                    # Try to convert to a single-element array if nulls are allowed
                    return [parse_value(value, field_type.elementType)]
                else:
                    raise ValueError(f"Expected a list for ArrayType, got {type(value)}")
            return [parse_value(v, field_type.elementType) for v in value]
        elif isinstance(field_type, MapType):
            # Handle MapType - new support
            if not isinstance(value, dict):
                raise ValueError(f"Expected a dictionary for MapType, got {type(value)}")
            return {
                parse_value(k, field_type.keyType): parse_value(v, field_type.valueType)
                for k, v in value.items()
            }
        # Handle primitive types with more robust error handling and type conversion
        try:
            if isinstance(field_type, StringType):
                # Don't convert None to "None" string
                return str(value) if value is not None else None
            elif isinstance(field_type, (IntegerType, LongType)):
                # Convert numeric strings and floats to integers
                if isinstance(value, str) and value.strip():
                    # Handle numeric strings
                    if "." in value:
                        return int(float(value))
                    return int(value)
                elif isinstance(value, (int, float)):
                    return int(value)
                raise ValueError(f"Cannot convert {value} to integer")
            elif isinstance(field_type, FloatType) or isinstance(field_type, DoubleType):
                # New support for floating point types
                if isinstance(value, str) and value.strip():
                    return float(value)
                return float(value)
            elif isinstance(field_type, DecimalType):
                # New support for Decimal type

                if isinstance(value, str) and value.strip():
                    return Decimal(value)
                return Decimal(str(value))
            elif isinstance(field_type, BooleanType):
                # Enhanced boolean conversion
                if isinstance(value, str):
                    lowered = value.lower()
                    if lowered in ("true", "t", "yes", "y", "1"):
                        return True
                    elif lowered in ("false", "f", "no", "n", "0"):
                        return False
                return bool(value)
            elif isinstance(field_type, DateType):
                # New support for DateType
                if isinstance(value, str):
                    # Try multiple date formats
                    for fmt in ("%Y-%m-%d", "%m/%d/%Y", "%d-%m-%Y", "%Y/%m/%d"):
                        try:
                            return datetime.strptime(value, fmt).date()
                        except ValueError:
                            continue
                    # ISO format as fallback
                    return datetime.fromisoformat(value).date()
                elif isinstance(value, datetime):
                    return value.date()
                raise ValueError(f"Cannot convert {value} to date")
            elif isinstance(field_type, TimestampType):
                # Enhanced timestamp handling
                if isinstance(value, str):
                    # Handle multiple timestamp formats including Z and timezone offsets
                    if value.endswith("Z"):
                        value = value.replace("Z", "+00:00")
                    try:
                        return datetime.fromisoformat(value)
                    except ValueError:
                        # Try additional formats if ISO format fails
                        for fmt in ("%Y-%m-%d %H:%M:%S", "%Y/%m/%d %H:%M:%S"):
                            try:
                                return datetime.strptime(value, fmt)
                            except ValueError:
                                continue
                elif isinstance(value, (int, float)):
                    # Handle Unix timestamps
                    return datetime.fromtimestamp(value)
                elif isinstance(value, datetime):
                    return value
                raise ValueError(f"Cannot convert {value} to timestamp")
            else:
                # Check for custom UDT handling
                if hasattr(field_type, "fromJson"):
                    # Support for User Defined Types that implement fromJson
                    return field_type.fromJson(value)
                raise TypeError(f"Unsupported field type: {field_type}")
        except (ValueError, TypeError) as e:
            # Add context to the error
            raise ValueError(f"Error converting '{value}' ({type(value)}) to {field_type}: {str(e)}")


    ########################################################
    # sources/googlemaps/googlemaps.py
    ########################################################

    class LakeflowConnect:
        """
        Google Maps Places API connector for Lakeflow.

        This connector uses the Places API (New) Text Search endpoint to retrieve
        place data based on text queries.
        """

        def __init__(self, options: Dict[str, str]) -> None:
            """
            Initialize the Google Maps Places connector.

            Args:
                options: Dictionary containing:
                    - api_key: Google Maps Platform API key
            """
            self.api_key = options["api_key"]
            self.base_url = "https://places.googleapis.com/v1"

            # Default field mask for the API requests - requesting most useful fields
            self._default_field_mask = ",".join([
                "places.id",
                "places.displayName",
                "places.formattedAddress",
                "places.shortFormattedAddress",
                "places.addressComponents",
                "places.location",
                "places.viewport",
                "places.googleMapsUri",
                "places.websiteUri",
                "places.internationalPhoneNumber",
                "places.nationalPhoneNumber",
                "places.types",
                "places.primaryType",
                "places.primaryTypeDisplayName",
                "places.businessStatus",
                "places.priceLevel",
                "places.rating",
                "places.userRatingCount",
                "places.currentOpeningHours",
                "places.regularOpeningHours",
                "places.utcOffsetMinutes",
                "places.editorialSummary",
                "places.iconMaskBaseUri",
                "places.iconBackgroundColor",
                "places.takeout",
                "places.delivery",
                "places.dineIn",
                "places.reservable",
                "places.servesBreakfast",
                "places.servesLunch",
                "places.servesDinner",
                "places.servesBeer",
                "places.servesWine",
                "places.servesBrunch",
                "places.servesVegetarianFood",
                "places.outdoorSeating",
                "places.liveMusic",
                "places.menuForChildren",
                "places.goodForChildren",
                "places.allowsDogs",
                "places.goodForGroups",
                "places.goodForWatchingSports",
                "places.accessibilityOptions",
                "places.parkingOptions",
                "places.paymentOptions",
                "places.plusCode",
                "places.adrFormatAddress",
                "nextPageToken",
            ])

            # Nested schema for displayName
            self._display_name_schema = StructType([
                StructField("text", StringType(), True),
                StructField("languageCode", StringType(), True),
            ])

            # Nested schema for location
            self._location_schema = StructType([
                StructField("latitude", DoubleType(), True),
                StructField("longitude", DoubleType(), True),
            ])

            # Nested schema for viewport
            self._viewport_schema = StructType([
                StructField("low", self._location_schema, True),
                StructField("high", self._location_schema, True),
            ])

            # Nested schema for address component
            self._address_component_schema = StructType([
                StructField("longText", StringType(), True),
                StructField("shortText", StringType(), True),
                StructField("types", ArrayType(StringType()), True),
                StructField("languageCode", StringType(), True),
            ])

            # Nested schema for opening hours period point
            self._period_point_schema = StructType([
                StructField("day", LongType(), True),
                StructField("hour", LongType(), True),
                StructField("minute", LongType(), True),
            ])

            # Nested schema for opening hours period
            self._period_schema = StructType([
                StructField("open", self._period_point_schema, True),
                StructField("close", self._period_point_schema, True),
            ])

            # Nested schema for opening hours
            self._opening_hours_schema = StructType([
                StructField("openNow", BooleanType(), True),
                StructField("periods", ArrayType(self._period_schema), True),
                StructField("weekdayDescriptions", ArrayType(StringType()), True),
            ])

            # Nested schema for editorial summary
            self._editorial_summary_schema = StructType([
                StructField("text", StringType(), True),
                StructField("languageCode", StringType(), True),
            ])

            # Nested schema for accessibility options
            self._accessibility_options_schema = StructType([
                StructField("wheelchairAccessibleParking", BooleanType(), True),
                StructField("wheelchairAccessibleEntrance", BooleanType(), True),
                StructField("wheelchairAccessibleRestroom", BooleanType(), True),
                StructField("wheelchairAccessibleSeating", BooleanType(), True),
            ])

            # Nested schema for parking options
            self._parking_options_schema = StructType([
                StructField("freeParking", BooleanType(), True),
                StructField("paidParking", BooleanType(), True),
                StructField("freeStreetParking", BooleanType(), True),
                StructField("paidStreetParking", BooleanType(), True),
                StructField("valetParking", BooleanType(), True),
                StructField("freeGarageParking", BooleanType(), True),
                StructField("paidGarageParking", BooleanType(), True),
            ])

            # Nested schema for payment options
            self._payment_options_schema = StructType([
                StructField("acceptsCreditCards", BooleanType(), True),
                StructField("acceptsDebitCards", BooleanType(), True),
                StructField("acceptsCashOnly", BooleanType(), True),
                StructField("acceptsNfc", BooleanType(), True),
            ])

            # Nested schema for plus code
            self._plus_code_schema = StructType([
                StructField("globalCode", StringType(), True),
                StructField("compoundCode", StringType(), True),
            ])

            # Full places schema
            self._places_schema = StructType([
                StructField("id", StringType(), False),
                StructField("displayName", self._display_name_schema, True),
                StructField("formattedAddress", StringType(), True),
                StructField("shortFormattedAddress", StringType(), True),
                StructField("addressComponents", ArrayType(self._address_component_schema), True),
                StructField("location", self._location_schema, True),
                StructField("viewport", self._viewport_schema, True),
                StructField("googleMapsUri", StringType(), True),
                StructField("websiteUri", StringType(), True),
                StructField("internationalPhoneNumber", StringType(), True),
                StructField("nationalPhoneNumber", StringType(), True),
                StructField("types", ArrayType(StringType()), True),
                StructField("primaryType", StringType(), True),
                StructField("primaryTypeDisplayName", self._display_name_schema, True),
                StructField("businessStatus", StringType(), True),
                StructField("priceLevel", StringType(), True),
                StructField("rating", DoubleType(), True),
                StructField("userRatingCount", LongType(), True),
                StructField("currentOpeningHours", self._opening_hours_schema, True),
                StructField("regularOpeningHours", self._opening_hours_schema, True),
                StructField("utcOffsetMinutes", LongType(), True),
                StructField("editorialSummary", self._editorial_summary_schema, True),
                StructField("iconMaskBaseUri", StringType(), True),
                StructField("iconBackgroundColor", StringType(), True),
                StructField("takeout", BooleanType(), True),
                StructField("delivery", BooleanType(), True),
                StructField("dineIn", BooleanType(), True),
                StructField("reservable", BooleanType(), True),
                StructField("servesBreakfast", BooleanType(), True),
                StructField("servesLunch", BooleanType(), True),
                StructField("servesDinner", BooleanType(), True),
                StructField("servesBeer", BooleanType(), True),
                StructField("servesWine", BooleanType(), True),
                StructField("servesBrunch", BooleanType(), True),
                StructField("servesVegetarianFood", BooleanType(), True),
                StructField("outdoorSeating", BooleanType(), True),
                StructField("liveMusic", BooleanType(), True),
                StructField("menuForChildren", BooleanType(), True),
                StructField("goodForChildren", BooleanType(), True),
                StructField("allowsDogs", BooleanType(), True),
                StructField("goodForGroups", BooleanType(), True),
                StructField("goodForWatchingSports", BooleanType(), True),
                StructField("accessibilityOptions", self._accessibility_options_schema, True),
                StructField("parkingOptions", self._parking_options_schema, True),
                StructField("paymentOptions", self._payment_options_schema, True),
                StructField("plusCode", self._plus_code_schema, True),
                StructField("adrFormatAddress", StringType(), True),
            ])

            # Object configuration
            self._object_config = {
                "places": {
                    "primary_keys": ["id"],
                    "ingestion_type": "snapshot",  # No incremental support for Places API
                },
            }

        def list_tables(self) -> List[str]:
            """
            List available tables/objects.

            Returns:
                List of supported table names
            """
            return ["places"]

        def get_table_schema(
            self, table_name: str, table_options: Dict[str, str]
        ) -> StructType:
            """
            Get the Spark schema for a table.

            Args:
                table_name: Name of the table
                table_options: Additional options (not used for schema)

            Returns:
                StructType representing the table schema
            """
            if table_name != "places":
                raise ValueError(
                    f"Unsupported table: {table_name}. Supported tables are: {self.list_tables()}"
                )
            return self._places_schema

        def read_table_metadata(
            self, table_name: str, table_options: Dict[str, str]
        ) -> Dict[str, Any]:
            """
            Get metadata for a table.

            Args:
                table_name: Name of the table
                table_options: Additional options (not used for metadata)

            Returns:
                Dictionary with primary_keys and ingestion_type
            """
            if table_name not in self._object_config:
                raise ValueError(
                    f"Unsupported table: {table_name}. Supported tables are: {self.list_tables()}"
                )
            config = self._object_config[table_name]
            return {
                "primary_keys": config["primary_keys"],
                "ingestion_type": config["ingestion_type"],
            }

        def read_table(
            self, table_name: str, start_offset: Dict, table_options: Dict[str, str]
        ) -> Tuple[Iterator[Dict], Dict]:
            """
            Read data from the places table using Text Search API.

            Args:
                table_name: Name of the table to read (must be "places")
                start_offset: Not used for snapshot ingestion (Places API doesn't support incremental)
                table_options: Dictionary containing:
                    - text_query: Required. The search query (e.g., "restaurants in Seattle")
                    - language_code: Optional. Language code for results (e.g., "en")
                    - max_result_count: Optional. Maximum results per page (1-20, default 20)
                    - included_type: Optional. Restrict to specific place type
                    - min_rating: Optional. Minimum average rating filter
                    - open_now: Optional. Only return places open now ("true"/"false")
                    - region_code: Optional. Region code for biasing (e.g., "US")

            Returns:
                Tuple of (iterator of place records, empty offset dict)
            """
            if table_name != "places":
                raise ValueError(f"Unsupported table: {table_name}")

            # Validate required parameter
            text_query = table_options.get("text_query")
            if not text_query:
                raise ValueError(
                    "table_options must include 'text_query' parameter for the places table"
                )

            # Build request parameters
            request_body = {
                "textQuery": text_query,
            }

            # Add optional parameters
            if "language_code" in table_options:
                request_body["languageCode"] = table_options["language_code"]

            if "max_result_count" in table_options:
                request_body["maxResultCount"] = int(table_options["max_result_count"])

            if "included_type" in table_options:
                request_body["includedType"] = table_options["included_type"]

            if "min_rating" in table_options:
                request_body["minRating"] = float(table_options["min_rating"])

            if "open_now" in table_options:
                request_body["openNow"] = table_options["open_now"].lower() == "true"

            if "region_code" in table_options:
                request_body["regionCode"] = table_options["region_code"]

            # Create iterator that yields places
            def places_iterator() -> Iterator[Dict]:
                current_body = request_body.copy()
                page_count = 0
                max_pages = 3  # Google Places API allows max 60 results (3 pages of 20)

                while page_count < max_pages:
                    # Make API request
                    response = requests.post(
                        f"{self.base_url}/places:searchText",
                        headers={
                            "Content-Type": "application/json",
                            "X-Goog-Api-Key": self.api_key,
                            "X-Goog-FieldMask": self._default_field_mask,
                        },
                        json=current_body,
                    )

                    if response.status_code != 200:
                        raise Exception(
                            f"Google Places API error: {response.status_code} {response.text}"
                        )

                    data = response.json()
                    places = data.get("places", [])

                    # Yield each place
                    for place in places:
                        yield place

                    # Check for next page
                    next_page_token = data.get("nextPageToken")
                    if not next_page_token:
                        break

                    # Update request for next page
                    current_body["pageToken"] = next_page_token
                    page_count += 1

            # For snapshot ingestion, offset is empty
            return places_iterator(), {}

        def test_connection(self) -> Dict[str, str]:
            """
            Test the connection to Google Places API.

            Returns:
                Dictionary with status and message
            """
            try:
                # Simple test query
                response = requests.post(
                    f"{self.base_url}/places:searchText",
                    headers={
                        "Content-Type": "application/json",
                        "X-Goog-Api-Key": self.api_key,
                        "X-Goog-FieldMask": "places.id",
                    },
                    json={
                        "textQuery": "test",
                        "maxResultCount": 1,
                    },
                )

                if response.status_code == 200:
                    return {"status": "success", "message": "Connection successful"}
                else:
                    return {
                        "status": "error",
                        "message": f"API error: {response.status_code} {response.text}",
                    }
            except Exception as e:
                return {"status": "error", "message": f"Connection failed: {str(e)}"}


    ########################################################
    # pipeline/lakeflow_python_source.py
    ########################################################

    METADATA_TABLE = "_lakeflow_metadata"
    TABLE_NAME = "tableName"
    TABLE_NAME_LIST = "tableNameList"


    class LakeflowStreamReader(SimpleDataSourceStreamReader):
        """
        Implements a data source stream reader for Lakeflow Connect.
        Currently, only the simpleStreamReader is implemented, which uses a
        more generic protocol suitable for most data sources that support
        incremental loading.
        """

        def __init__(
            self,
            options: dict[str, str],
            schema: StructType,
            lakeflow_connect: LakeflowConnect,
        ):
            self.options = options
            self.lakeflow_connect = lakeflow_connect
            self.schema = schema

        def initialOffset(self):
            return {}

        def read(self, start: dict) -> (Iterator[tuple], dict):
            records, offset = self.lakeflow_connect.read_table(
                self.options["tableName"], start, self.options
            )
            rows = map(lambda x: parse_value(x, self.schema), records)
            return rows, offset

        def readBetweenOffsets(self, start: dict, end: dict) -> Iterator[tuple]:
            # TODO: This does not ensure the records returned are identical across repeated calls.
            # For append-only tables, the data source must guarantee that reading from the same
            # start offset will always yield the same set of records.
            # For tables ingested as incremental CDC, it is only necessary that no new changes
            # are missed in the returned records.
            return self.read(start)[0]


    class LakeflowBatchReader(DataSourceReader):
        def __init__(
            self,
            options: dict[str, str],
            schema: StructType,
            lakeflow_connect: LakeflowConnect,
        ):
            self.options = options
            self.schema = schema
            self.lakeflow_connect = lakeflow_connect
            self.table_name = options[TABLE_NAME]

        def read(self, partition):
            all_records = []
            if self.table_name == METADATA_TABLE:
                all_records = self._read_table_metadata()
            else:
                all_records, _ = self.lakeflow_connect.read_table(
                    self.table_name, None, self.options
                )

            rows = map(lambda x: parse_value(x, self.schema), all_records)
            return iter(rows)

        def _read_table_metadata(self):
            table_name_list = self.options.get(TABLE_NAME_LIST, "")
            table_names = [o.strip() for o in table_name_list.split(",") if o.strip()]
            all_records = []
            for table in table_names:
                metadata = self.lakeflow_connect.read_table_metadata(table, self.options)
                all_records.append({"tableName": table, **metadata})
            return all_records


    class LakeflowSource(DataSource):
        def __init__(self, options):
            self.options = options
            self.lakeflow_connect = LakeflowConnect(options)

        @classmethod
        def name(cls):
            return "lakeflow_connect"

        def schema(self):
            table = self.options["tableName"]
            if table == METADATA_TABLE:
                return StructType(
                    [
                        StructField("tableName", StringType(), False),
                        StructField("primary_keys", ArrayType(StringType()), True),
                        StructField("cursor_field", StringType(), True),
                        StructField("ingestion_type", StringType(), True),
                    ]
                )
            else:
                # Assuming the LakeflowConnect interface uses get_table_schema, not get_table_details
                return self.lakeflow_connect.get_table_schema(table, self.options)

        def reader(self, schema: StructType):
            return LakeflowBatchReader(self.options, schema, self.lakeflow_connect)

        def simpleStreamReader(self, schema: StructType):
            return LakeflowStreamReader(self.options, schema, self.lakeflow_connect)


    spark.dataSource.register(LakeflowSource)  # pylint: disable=undefined-variable
